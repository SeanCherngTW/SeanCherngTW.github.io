<!DOCTYPE HTML>
<html lang="default">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>三種RNN Cell之output和state的差異 | Sean Chenrg&#39;s Blog</title>
  <meta name="author" content="Sean Cherng">
  
  <meta name="description" content="Introduction我們在使用TensorFlow建立RNN架構時，會看到dynamic_rnn()的輸出有兩個，一個是outputs，另一個是state：123456789101112# create a BasicRNNCellrnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size)# &#39;outputs&#39; is a tensor of shape [batch_size, max_time, cell_state_size]# defining initial stateinitial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)# &#39;state&#39; is a tensor of shape [batch_size, cell_state_size]outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,                                   initial_state=initial_state,                                   dtype=tf.float32)
有些網路上的教學會說output和state是相同的，但實際用起來好像有時候也不相同，所以就讓我們來從三種RNN Cell的角度來分析一下。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="三種RNN Cell之output和state的差異"/>
  <meta property="og:site_name" content="Sean Chenrg&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Sean Chenrg&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Sean Chenrg&#39;s Blog</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article id="post-三種RNN-Cell之output和state差異" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-30T13:18:33.000Z"><a href="/2020/01/30/三種RNN-Cell之output和state差異/">2020-01-30</a></time>
      
      
  
    <h1 class="p-name title" itemprop="headline name">三種RNN Cell之output和state的差異</h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>我們在使用TensorFlow建立RNN架構時，會看到dynamic_rnn()的輸出有兩個，一個是outputs，另一個是state：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create a BasicRNNCell</span></div><div class="line">rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size)</div><div class="line"></div><div class="line"><span class="comment"># 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]</span></div><div class="line"></div><div class="line"><span class="comment"># defining initial state</span></div><div class="line">initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)</div><div class="line"></div><div class="line"><span class="comment"># 'state' is a tensor of shape [batch_size, cell_state_size]</span></div><div class="line">outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,</div><div class="line">                                   initial_state=initial_state,</div><div class="line">                                   dtype=tf.float32)</div></pre></td></tr></table></figure></p>
<p>有些網路上的教學會說output和state是相同的，但實際用起來好像有時候也不相同，所以就讓我們來從三種RNN Cell的角度來分析一下。</p>
<a id="more"></a>
<h3 id="Basic-RNN-Cell"><a href="#Basic-RNN-Cell" class="headerlink" title="Basic RNN Cell"></a>Basic RNN Cell</h3><p>最簡單的RNN Cell如圖：<br><br></p>
<p><img src="https://i.imgur.com/683CSh5.png" alt=""><br><br></p>
<ul>
<li><script type="math/tex">x^t</script> 為在時間點 <script type="math/tex">t</script> 的輸入</li>
<li><script type="math/tex">h^{t-1}</script> 為時間點 <script type="math/tex">t-1</script> 的輸出</li>
<li><script type="math/tex">h^{t}</script> 為時間點 <script type="math/tex">t</script> 的輸出。</li>
</ul>
<p>在基本單層RNN Cell中，以時間點<script type="math/tex">t</script>來看，output和state的值都是<script type="math/tex">h^{t}</script>。但是如果有使用深層架構，那兩者就會不相同，我會在下面解釋這兩者之間的差異。</p>
<h3 id="LSTM-Cell"><a href="#LSTM-Cell" class="headerlink" title="LSTM Cell"></a>LSTM Cell</h3><p>相較於Basic RNN Cell，LSTM Cell新增了三個用於控制資訊流量的閘門，分別為Forget gate, Input gate和Output gate，如下圖所示：<br><br></p>
<p><img src="https://i.imgur.com/9mTC4iS.png" alt=""><br><br></p>
<ul>
<li><script type="math/tex">x^t</script> 為在時間點 <script type="math/tex">t</script> 的輸入</li>
<li><script type="math/tex">f^{t}</script> 為Forget gate，用來控制要保留或捨去多少比例的記憶</li>
<li><script type="math/tex">i^{t}</script> 為Input gate，用來控制要保留或捨去多少比例的輸入</li>
<li><script type="math/tex">o^t</script> 為Output gate，用來控制要保留或捨去多少比例的最後輸出</li>
<li><script type="math/tex">h^{t-1}</script> 為時間點 <script type="math/tex">t-1</script> 時的輸出</li>
<li><script type="math/tex">{h^{t}}</script> 為時間點 <script type="math/tex">t</script> 時的輸出</li>
<li><script type="math/tex">c^{t-1}</script> 為時間點 <script type="math/tex">c-1</script> 時的記憶</li>
<li><script type="math/tex">c^{t}</script> 則為時間點 <script type="math/tex">c</script> 時的記憶</li>
</ul>
<p>我們使用單層LSTM時，呼叫<code>outputs, state = tf.compat.v1.nn.dynamic_rnn()</code>所得到的<code>output</code>在 <script type="math/tex">t</script> 時間是 <script type="math/tex">{h^{t}}</script> ，但state會是 <script type="math/tex">[{c^t},{h^{t}}]</script>，因此兩者不同。若使用深層LSTM架構時，如下圖：<br><br></p>
<p><img src="https://i.imgur.com/Fti66rk.png" alt=""><br><br></p>
<p>以 <script type="math/tex">t+1</script> 時間點為例，output為最後一層的 <script type="math/tex">t+1</script> 時間點輸出，是 <script type="math/tex">{h^{t+1}_{l+2}}</script>，而state則是每一層的 <script type="math/tex">t+1</script> 時間點的 <script type="math/tex">c^{t+1}</script> <script type="math/tex">h^{t+1}</script> 結合成的list，也就是<script type="math/tex">[[c^{t-1},h^{t-1}], [c^{t}, h^{t}], [c^{t+1}, h^{t+1}]]</script>。因此在LSTM Cell的狀況下，不管單層或多層，output和state都不會相等。</p>
<h3 id="GRU-Cell"><a href="#GRU-Cell" class="headerlink" title="GRU Cell"></a>GRU Cell</h3><p>相較於LSTM Cell，GRU Cell使用了Memory gate取代Input gate和Forget gate，讓參數可以有效減少，同時GRU也不像LSTM有 <script type="math/tex">c^t</script> 來儲存記憶狀態，如下圖所示：<br><br></p>
<p><img src="https://i.imgur.com/nNWbaPo.png" alt=""><br><br></p>
<ul>
<li><script type="math/tex">x^t</script> 為在時間點 <script type="math/tex">t</script> 的輸入</li>
<li><script type="math/tex; mode=display">u^t$$ Memory gate，用來控制要保留或捨去多少比例的$$C^{t-1}</script></li>
<li><script type="math/tex">h^{t-1}</script> 為時間點 <script type="math/tex">t-1</script> 的輸出</li>
<li><script type="math/tex">{h^{t}}</script> 為時間點 <script type="math/tex">t</script> 的輸出</li>
</ul>
<p>我們使用單層LSTM時，呼叫<code>outputs, state = tf.compat.v1.nn.dynamic_rnn()</code>所得到的<code>output</code>在 <script type="math/tex">t</script> 時間是 <script type="math/tex">{h^{t}}</script> ，state也是 <script type="math/tex">{h^{t}}</script>，因此和Basic RNN Cell一樣，兩者相等。若使用深層LSTM架構時，如下圖：<br><br></p>
<p><img src="https://i.imgur.com/iLatvSM.png" alt=""><br><br></p>
<p>以 <script type="math/tex">t+1</script> 時間點為例，output為最後一層的 <script type="math/tex">t+1</script> 時間點輸出，是 <script type="math/tex">{h^{t+1}_{l+2}}</script>，而state則是每一層的 <script type="math/tex">t+1</script> 時間點的 <script type="math/tex">c^{t+1}</script> <script type="math/tex">h^{t+1}</script> 結合成的list，也就是<script type="math/tex">[h^{t-1}, h^{t}, h^{t+1}]</script>。GRU Cell的狀況下，只有單層架構時output和state會相等</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>單層架構時output和state相等，多層架構時不相等：</p>
<ul>
<li>Basic RNN Cell</li>
<li>GRU Cell</li>
</ul>
<p>不論單層或多層，output和state都不相等:</p>
<ul>
<li>LSTM Cell (因為state包含了記憶狀態 <script type="math/tex">c{t}</script>)</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://zhuanlan.zhihu.com/p/28919765" target="_blank" rel="external">学会区分 RNN 的 output 和 state</a><br><a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/dynamic_rnn" target="_blank" rel="external">dynamic_rnn()官方文件</a></p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/深度學習/">深度學習</a>, <a href="/tags/TensorFlow/">TensorFlow</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="https://seancherngtw.github.io/2020/01/30/三種RNN-Cell之output和state差異/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="as_sitesearch" value="seancherngtw.github.io">
  </form>
</div>


  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/Jupyter-Notebook/">Jupyter Notebook</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>3</small></li>
  
    <li><a href="/tags/Python/">Python</a><small>1</small></li>
  
    <li><a href="/tags/TensorFlow/">TensorFlow</a><small>2</small></li>
  
    <li><a href="/tags/李宏毅機器學習筆記/">李宏毅機器學習筆記</a><small>5</small></li>
  
    <li><a href="/tags/深度學習/">深度學習</a><small>4</small></li>
  
    <li><a href="/tags/網頁爬蟲/">網頁爬蟲</a><small>1</small></li>
  
    <li><a href="/tags/面試心得/">面試心得</a><small>3</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Sean Cherng
  
</div>
<div class="clearfix"></div></footer>
  <script src="/js/jquery-3.4.1.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'SeanCherngTW';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
