<!DOCTYPE HTML>
<html lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Sean Chenrg&#39;s Blog</title>
  <meta name="author" content="Sean Cherng">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Sean Chenrg&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Sean Chenrg&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Sean Chenrg&#39;s Blog</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article id="post-使用SavedModel和Predictor方便地將TensorFlow模型架設於Flask上" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-02-04T04:14:18.000Z"><a href="/2020/02/04/使用SavedModel和Predictor方便地將TensorFlow模型架設於Flask上/">2020-02-04</a></time>
      
      
  
    <h1 class="title"><a href="/2020/02/04/使用SavedModel和Predictor方便地將TensorFlow模型架設於Flask上/">使用SavedModel和Predictor方便地將TensorFlow模型架設於Flask上</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>當我們訓練好一個模型後，可能會需要把它透過Flask架設成一個web service，而我們希望在server開啟時能夠讀入模型，每當之後呼叫API時，能直接讀取這個模型進行預測，而不是每次call API後才讀取Model。</p>
<h3 id="Previous-method"><a href="#Previous-method" class="headerlink" title="Previous method"></a>Previous method</h3><p>以往在儲存TensorFlow模型時，多半在Session內建立Saver，並透過<figure class="highlight plain"><figcaption><span>API後才讀取Model」</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">### SavedModel &amp; Predictor</div><div class="line">所以，我們希望能跳脫Session這個框架來完成我們的目標，這次要介紹的方法是```SavedModel```和```Predictor```。```SavedModel```用來儲存模型參數，```Predictor```用來讀取模型參數後直接進行預測，這邊我借用莫凡Tensorflow的範例來解釋：</div><div class="line"></div><div class="line">#### SavedModel</div><div class="line"></div><div class="line">```python=</div><div class="line">import tensorflow as tf</div><div class="line">import tensorflow.examples.tutorials.mnist.input_data as input_data</div><div class="line">from tensorflow.contrib import predictor</div><div class="line"></div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</div><div class="line"></div><div class="line"></div><div class="line">def train():</div><div class="line">    def add_layer(output_dim, input_dim, inputs, activation_function=None):</div><div class="line">        W = tf.Variable(tf.random_normal([input_dim, output_dim]))</div><div class="line">        b = tf.Variable(tf.random_normal([1, output_dim]))</div><div class="line">        if activation_function is None:</div><div class="line">            outputs = tf.add(tf.matmul(inputs, W), b)</div><div class="line">        else:</div><div class="line">            outputs = activation_function(tf.add(tf.matmul(inputs, W), b))</div><div class="line">        return outputs</div><div class="line">    X = tf.placeholder(&apos;float&apos;, [None, 784])</div><div class="line">    h1 = add_layer(output_dim=1000, input_dim=784, inputs=X, activation_function=tf.nn.relu)</div><div class="line">    y = add_layer(output_dim=10, input_dim=1000, inputs=h1, activation_function=None)</div><div class="line">    y_hat = tf.placeholder(&apos;float&apos;, [None, 10])</div><div class="line"></div><div class="line">    loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_hat))</div><div class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss_function)</div><div class="line">    correct_prediction_count = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))</div><div class="line">    acc = tf.reduce_mean(tf.cast(correct_prediction_count, &apos;float&apos;), name=&apos;acc&apos;)</div><div class="line"></div><div class="line">    epoch = 15</div><div class="line">    batch_size = 100</div><div class="line">    batch = int(mnist.train.num_examples / batch_size)</div><div class="line"></div><div class="line">    with tf.Session() as sess:</div><div class="line">        sess.run(tf.global_variables_initializer())</div><div class="line">        for i in range(epoch):</div><div class="line">            for _ in range(batch):</div><div class="line">                batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">                sess.run(optimizer, feed_dict=&#123;X: batch_x, y_hat: batch_y&#125;)</div><div class="line"></div><div class="line">        tf.saved_model.simple_save(sess, &quot;./savemodel&quot;, inputs=&#123;&quot;input_X&quot;: X, &quot;y_hat&quot;: y_hat&#125;, outputs=&#123;&quot;output_y&quot;: y, &quot;acc&quot;: acc&#125;)</div><div class="line"></div><div class="line"></div><div class="line">train()</div></pre></td></tr></table></figure></p>
<p>在這個例子中，我們在<figure class="highlight plain"><figcaption><span>"./savemodel", inputs</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">#### Predictor</div><div class="line">```python=</div><div class="line">def testacc():</div><div class="line">    predict_fn = predictor.from_saved_model(&apos;savemodel/&apos;)</div><div class="line">    acc = predict_fn(&#123;</div><div class="line">        &quot;input_X&quot;: mnist.test.images,</div><div class="line">        &quot;y_hat&quot;: mnist.test.labels</div><div class="line">    &#125;)[&quot;acc&quot;]</div><div class="line">    print(acc)</div><div class="line"></div><div class="line">def pred():</div><div class="line">    predict_fn = predictor.from_saved_model(&apos;savemodel/&apos;)</div><div class="line">    pred = predict_fn(&#123;</div><div class="line">        &quot;input_X&quot;: mnist.test.images,</div><div class="line">        &quot;y_hat&quot;: mnist.test.labels</div><div class="line">    &#125;)[&quot;output_y&quot;]</div><div class="line">    return pred</div><div class="line"></div><div class="line">testacc()</div><div class="line">pred()</div></pre></td></tr></table></figure></p>
<p>當我們要讀取模型參數進行預測時，直接呼叫<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">如此一來，我們不必透過Session和Saver，就可以達到Save&amp;Retore的效果</div><div class="line"></div><div class="line">#### Flask</div><div class="line">跳脫Session框架後，即可更便利地將模型架設在Flask上，完整程式碼如下：</div></pre></td></tr></table></figure></p>
<p>import flask<br>import tensorflow as tf<br>import tensorflow.examples.tutorials.mnist.input_data as input_data<br>from tensorflow.contrib import predictor</p>
<p>app = flask.Flask(<strong>name</strong>)</p>
<p>mnist = input_data.read_data_sets(“MNIST_data/“, one_hot=True)</p>
<p>@app.route(‘/testacc’, methods=[‘GET’])<br>def testacc():<br>    predict_fn = predictor.from_saved_model(‘savemodel/‘)<br>    acc = predict_fn({<br>        “input_X”: mnist.test.images,<br>        “y_hat”: mnist.test.labels<br>    })[“acc”]<br>    print(pred)<br>    return acc</p>
<p>@app.route(‘/pred’, methods=[‘GET’])<br>def pred():<br>    predict_fn = predictor.from_saved_model(‘savemodel/‘)<br>    pred = predict_fn({<br>        “input_X”: mnist.test.images,<br>        “y_hat”: mnist.test.labels<br>    })[“output_y”]<br>    return pred</p>
<p>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    app.debug = True<br>    app.run()<br>```</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://guillaumegenthial.github.io/serving-tensorflow-estimator.html#training-the-estimator" target="_blank" rel="external">Save and Restore a tf.estimator for inference</a><br><a href="https://juejin.im/post/5bbfedd65188255c9b13d964" target="_blank" rel="external">Tensorflow SavedModel模型的保存与加载</a><br><a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/predictor/from_saved_model?authuser=3&amp;hl=Language" target="_blank" rel="external">tf.contrib.predictor.from_saved_model</a><br><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/" target="_blank" rel="external">莫凡TensorFlow</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-透過ssh設定遠端Jupyter-Notebook" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-31T05:35:20.000Z"><a href="/2020/01/31/透過ssh設定遠端Jupyter-Notebook/">2020-01-31</a></time>
      
      
  
    <h1 class="title"><a href="/2020/01/31/透過ssh設定遠端Jupyter-Notebook/">透過ssh設定遠端Jupyter Notebook</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <ol>
<li>安裝jupyter notebook</li>
<li>移動到母目錄 cd ~</li>
<li><p>執行指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ jupyter notebook --generate-config</div></pre></td></tr></table></figure>
</li>
<li><p>執行指令設定密碼</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ jupyter notebook password</div></pre></td></tr></table></figure>
</li>
<li><p>去~/.jupyter/jupyter_notebook_config.json找到你密碼的SHA1</p>
</li>
<li>編輯 ~/.jupyter/jupyter_notebook_config.py如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.open_browser = False</div><div class="line">c.NotebookApp.password = u&apos;sha1:[YOUR SHA1]&apos;</div><div class="line">c.NotebookApp.password_required = True</div><div class="line">c.NotebookApp.port = [YOUR PORT] # 要確定這個PORT沒有人在用</div><div class="line">c.NotebookApp.ip = &apos;*&apos;</div></pre></td></tr></table></figure></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-三種RNN-Cell之output和state差異" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-30T13:18:33.000Z"><a href="/2020/01/30/三種RNN-Cell之output和state差異/">2020-01-30</a></time>
      
      
  
    <h1 class="title"><a href="/2020/01/30/三種RNN-Cell之output和state差異/">三種RNN Cell之output和state的差異</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>我們在使用TensorFlow建立RNN架構時，會看到dynamic_rnn()的輸出有兩個，一個是outputs，另一個是state：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create a BasicRNNCell</span></div><div class="line">rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size)</div><div class="line"></div><div class="line"><span class="comment"># 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]</span></div><div class="line"></div><div class="line"><span class="comment"># defining initial state</span></div><div class="line">initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)</div><div class="line"></div><div class="line"><span class="comment"># 'state' is a tensor of shape [batch_size, cell_state_size]</span></div><div class="line">outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,</div><div class="line">                                   initial_state=initial_state,</div><div class="line">                                   dtype=tf.float32)</div></pre></td></tr></table></figure></p>
<p>有些網路上的教學會說output和state是相同的，但實際用起來好像有時候也不相同，所以就讓我們來從三種RNN Cell的角度來分析一下。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/01/30/三種RNN-Cell之output和state差異/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ALBERT簡短重點整理" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-25T13:53:59.000Z"><a href="/2020/01/25/ALBERT簡短重點整理/">2020-01-25</a></time>
      
      
  
    <h1 class="title"><a href="/2020/01/25/ALBERT簡短重點整理/">ALBERT簡短重點整理</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>ALBERT主要對BERT做了3點改進，縮小了整體的參數量，加快了訓練速度，增加了模型效果。 <br><br>分別為Factorized embedding parameterization, Cross-layer parameter sharing, Inter-sentence coherence loss</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/01/25/ALBERT簡短重點整理/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-TinyBERT簡短重點整理" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-20T06:02:12.000Z"><a href="/2020/01/20/TinyBERT簡短重點整理/">2020-01-20</a></time>
      
      
  
    <h1 class="title"><a href="/2020/01/20/TinyBERT簡短重點整理/">TinyBERT簡短重點整理</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>TinyBERT 是華為、華科聯合提出的一種為基於transformer 的模型專門設計的知識蒸餾方法，模型大小不到BERT 的1/7，但速度提高了9 倍，而且性能沒有出現明顯下降<br>主要目標：減少transformer encoding 的層數和hidden size 大小</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/01/20/TinyBERT簡短重點整理/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-XLNet簡短重點整理" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-16T17:11:26.000Z"><a href="/2020/01/17/XLNet簡短重點整理/">2020-01-17</a></time>
      
      
  
    <h1 class="title"><a href="/2020/01/17/XLNet簡短重點整理/">XLNet簡短重點整理</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>XLNet的想法就是要使用Auto Regressive的方式來預測單詞（用{x1, x2,…, xt-1}預測xt），但是這種作法在預測xt的時候只能得到x1~xt-1的forward資訊，得不到backward資訊。XLNet又要能在不使用Mask的前提下學習到上下文的資訊進行訓練，結合GPT和BERT的優點進行改良</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/01/17/XLNet簡短重點整理/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-10-Convolutional-Neural-Network" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-20T15:24:14.000Z"><a href="/2019/08/20/ML-Lecture-10-Convolutional-Neural-Network/">2019-08-20</a></time>
      
      
  
    <h1 class="title"><a href="/2019/08/20/ML-Lecture-10-Convolutional-Neural-Network/">ML Lecture 10: Convolutional Neural Network</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h4 id="圖像辨識使用CNN"><a href="#圖像辨識使用CNN" class="headerlink" title="圖像辨識使用CNN"></a>圖像辨識使用CNN</h4><ul>
<li>需要辨識的物體可能只佔了圖片的某一小塊（Convolution）</li>
<li>同樣的pattern在圖片中的不同地方仍然代表一樣的意思（Convolution）</li>
<li>圖片縮小後，仍然可以輕易地分辨出圖片中的物體（pooling）</li>
</ul>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2019/08/20/ML-Lecture-10-Convolutional-Neural-Network/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-3-1-Gradient-Descent" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T15:58:13.000Z"><a href="/2019/08/19/ML-Lecture-3-1-Gradient-Descent/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/2019/08/19/ML-Lecture-3-1-Gradient-Descent/">ML Lecture 3-1: Gradient Descent</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h4 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h4><ul>
<li>把輸入的特徵的值範圍調整成一致</li>
<li>可以想成標準化，平均=1、標準差=0</li>
<li>如此一來在做Gradient Descent時，可以讓梯度以直線往最低點前進，讓各參數不需要客製化自己的Learning rate
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2019/08/19/ML-Lecture-3-1-Gradient-Descent/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-2-Where-does-the-error-come-from" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T15:55:11.000Z"><a href="/2019/08/19/ML-Lecture-2-Where-does-the-error-come-from/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/2019/08/19/ML-Lecture-2-Where-does-the-error-come-from/">ML Lecture 2: Where does the error come from?</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>Variance / Bias</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2019/08/19/ML-Lecture-2-Where-does-the-error-come-from/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-1-Regression-Case-Study" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T03:01:45.000Z"><a href="/2019/08/19/ML-Lecture-1-Regression-Case-Study/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/2019/08/19/ML-Lecture-1-Regression-Case-Study/">ML Lecture 1: Regression - Case Study</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="ML三步驟"><a href="#ML三步驟" class="headerlink" title="ML三步驟"></a>ML三步驟</h3><ol>
<li>準備一組function set（設計model）<ul>
<li>可以把function set想成Model，不同的model代表不同function set</li>
<li>同一個model代表同一個function set，參數中不同的weight和bias就代表同一個function set中不同的function</li>
</ul>
</li>
<li>判斷function set中，每一個function的好壞<ul>
<li>使用Loss function來判斷function的好壞<ul>
<li>具體作法：把Training data的X作為輸入，計算function產出的y與實際的y相差多少，這個相差的值就稱為Loss（或error）</li>
<li>Loss越低，代表此function對於training data的擬合度很高，但對於testing data卻不一定也是如此（可能overfitting）</li>
</ul>
</li>
</ul>
</li>
<li>找出最佳的function<ul>
<li>使用Gradient Descent來決定function中的weight應該要如何修正<ul>
<li>function中會有很多參數（weight），對參數做偏微分後，即可得到該參數的斜率。將偏微分的結果（方向）乘上Learning rate（步伐），即可算出這個weight應該要增加或減少多少，目標是使Loss降到最低</li>
</ul>
</li>
</ul>
</li>
</ol>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2019/08/19/ML-Lecture-1-Regression-Case-Study/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
    <a href="/page/2/" class="alignright next">Nächste Seite</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="as_sitesearch" value="seancherngtw.github.io">
  </form>
</div>


  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/Jupyter-Notebook/">Jupyter Notebook</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>3</small></li>
  
    <li><a href="/tags/Python/">Python</a><small>1</small></li>
  
    <li><a href="/tags/TensorFlow/">TensorFlow</a><small>2</small></li>
  
    <li><a href="/tags/李宏毅機器學習筆記/">李宏毅機器學習筆記</a><small>5</small></li>
  
    <li><a href="/tags/深度學習/">深度學習</a><small>4</small></li>
  
    <li><a href="/tags/網頁爬蟲/">網頁爬蟲</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Sean Cherng
  
</div>
<div class="clearfix"></div></footer>
  <script src="/js/jquery-3.4.1.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'SeanCherngTW';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
