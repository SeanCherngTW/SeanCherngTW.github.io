<!DOCTYPE HTML>
<html lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Sean Chenrg&#39;s Blog</title>
  <meta name="author" content="Sean Cherng">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Sean Chenrg&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/SeanCherngTW.github.io/favicon.png" rel="icon">
  <link rel="alternate" href="/SeanCherngTW.github.io/atom.xml" title="Sean Chenrg&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/SeanCherngTW.github.io/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/SeanCherngTW.github.io/">Sean Chenrg&#39;s Blog</a></h1>
  <h2><a href="/SeanCherngTW.github.io/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/SeanCherngTW.github.io/">Home</a></li>
    
      <li><a href="/SeanCherngTW.github.io/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article id="post-透過ssh設定遠端Jupyter-Notebook" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-31T05:35:20.000Z"><a href="/SeanCherngTW.github.io/2020/01/31/透過ssh設定遠端Jupyter-Notebook/">2020-01-31</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2020/01/31/透過ssh設定遠端Jupyter-Notebook/">透過ssh設定遠端Jupyter Notebook</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <ol>
<li>安裝jupyter notebook</li>
<li>移動到母目錄 cd ~</li>
<li><p>執行指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ jupyter notebook --generate-config</div></pre></td></tr></table></figure>
</li>
<li><p>執行指令設定密碼</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ jupyter notebook password</div></pre></td></tr></table></figure>
</li>
<li><p>去~/.jupyter/jupyter_notebook_config.json找到你密碼的SHA1</p>
</li>
<li>編輯 ~/.jupyter/jupyter_notebook_config.py如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.open_browser = False</div><div class="line">c.NotebookApp.password = u&apos;sha1:[YOUR SHA1]&apos;</div><div class="line">c.NotebookApp.password_required = True</div><div class="line">c.NotebookApp.port = [YOUR PORT] # 要確定這個PORT沒有人在用</div><div class="line">c.NotebookApp.ip = &apos;*&apos;</div></pre></td></tr></table></figure></li>
</ol>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-三種RNN-Cell之output和state差異" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-30T13:18:33.000Z"><a href="/SeanCherngTW.github.io/2020/01/30/三種RNN-Cell之output和state差異/">2020-01-30</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2020/01/30/三種RNN-Cell之output和state差異/">三種RNN Cell之output和state的差異</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>我們在使用TensorFlow建立RNN架構時，會看到dynamic_rnn()的輸出有兩個，一個是outputs，另一個是state：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create a BasicRNNCell</span></div><div class="line">rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(hidden_size)</div><div class="line"></div><div class="line"><span class="comment"># 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]</span></div><div class="line"></div><div class="line"><span class="comment"># defining initial state</span></div><div class="line">initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)</div><div class="line"></div><div class="line"><span class="comment"># 'state' is a tensor of shape [batch_size, cell_state_size]</span></div><div class="line">outputs, state = tf.compat.v1.nn.dynamic_rnn(rnn_cell, input_data,</div><div class="line">                                   initial_state=initial_state,</div><div class="line">                                   dtype=tf.float32)</div></pre></td></tr></table></figure></p>
<p>有些網路上的教學會說output和state是相同的，但實際用起來好像有時候也不相同，所以就讓我們來從三種RNN Cell的角度來分析一下。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2020/01/30/三種RNN-Cell之output和state差異/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ALBERT簡短重點整理" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-25T13:53:59.000Z"><a href="/SeanCherngTW.github.io/2020/01/25/ALBERT簡短重點整理/">2020-01-25</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2020/01/25/ALBERT簡短重點整理/">ALBERT簡短重點整理</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p></p><h2> ALBERT </h2><br>ALBERT主要對BERT做了3點改進，縮小了整體的參數量，加快了訓練速度，增加了模型效果。 <br><br>分別為Factorized embedding parameterization, Cross-layer parameter sharing, Inter-sentence coherence loss<p></p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2020/01/25/ALBERT簡短重點整理/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-TinyBERT簡短重點整理" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-20T06:02:12.000Z"><a href="/SeanCherngTW.github.io/2020/01/20/TinyBERT簡短重點整理/">2020-01-20</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2020/01/20/TinyBERT簡短重點整理/">TinyBERT簡短重點整理</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h2 id="Tiny-BERT"><a href="#Tiny-BERT" class="headerlink" title="Tiny BERT"></a>Tiny BERT</h2><p>TinyBERT 是華為、華科聯合提出的一種為基於transformer 的模型專門設計的知識蒸餾方法，模型大小不到BERT 的1/7，但速度提高了9 倍，而且性能沒有出現明顯下降<br>主要目標：減少transformer encoding 的層數和hidden size 大小</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2020/01/20/TinyBERT簡短重點整理/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-XLNet簡短重點整理" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2020-01-16T17:11:26.000Z"><a href="/SeanCherngTW.github.io/2020/01/17/XLNet簡短重點整理/">2020-01-17</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2020/01/17/XLNet簡短重點整理/">XLNet簡短重點整理</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h2 id="XLnet"><a href="#XLnet" class="headerlink" title="XLnet"></a>XLnet</h2><h3 id="Auto-Regressive-AR"><a href="#Auto-Regressive-AR" class="headerlink" title="Auto Regressive (AR)"></a>Auto Regressive (AR)</h3><p><img src="https://i.imgur.com/zVnWFSs.png" alt=""><br>用前文預測後文，比如說用{x1, x2,…, xt-1}預測xt，主要應用在GPT和ELMO上，只能以單向的資訊去預測。ELMo雖然看似雙向架構，但其實他是訓練兩個單向LSTM後再concat起來，效果並不如真正的雙向架構<br><img src="https://i.imgur.com/l9zgF7d.png" alt=""></p>
<h3 id="Auto-Encoding-AE"><a href="#Auto-Encoding-AE" class="headerlink" title="Auto Encoding (AE)"></a>Auto Encoding (AE)</h3><p><img src="https://i.imgur.com/gT6yuPw.png" alt=""><br>把句子中其中一個字mask掉，去預測那個被mask的字。在Pre-train模型中首次有使用到DAE的模型就是BERT的MLM(Masked Language Model)。隨機把所有句子中15%的token使用Mask來替代，然後在預測時將Mask的位置預測成原來的字，把替換成Mask然後再還原的作法可以視為一種DAE，這種作法可以幫助預測Mask時充分運用到上下文的資訊。但這只有在Pre-train階段會用到，fine-tune階段時不會用到Mask，資料格式不相同的情況下作者認為這會影響到效能。</p>
<p><img src="https://i.imgur.com/7N8hOC9.png" alt=""></p>
<p>另外若同一個句子有兩個Mask，BERT的訓練方法是會將這兩個位置同時產生輸出，這代表了這兩個字會是獨立的，但如圖的x3, x4他們是有依賴關係的，所以必須使用AR方法改進，讓model先先預測x3再預測x4<br><img src="https://i.imgur.com/nOaWwS7.png" alt=""></p>
<h3 id="Permutation-Language-Modeling"><a href="#Permutation-Language-Modeling" class="headerlink" title="Permutation Language Modeling"></a>Permutation Language Modeling</h3><p>XLNet的想法就是要使用AR的方式來預測單詞，又要能在不使用Mask的前提下學習到上下文的資訊，所以XLNet提出的Permutation Language Modeling(PLM)，即使用permutation實現上下文對於單詞的預測，其實訓練方式還是transfomer的self-attention，只是對輸入與attention matrix進行一點修飾。<br><img src="https://i.imgur.com/Tp74VJw.png" alt=""></p>
<p>在訓練階段時，隨機對輸入句子的排序做排列組合，例如{x2, x4, x3, x1}，就能夠在預測x3時輸入x2和x4作為前後文資訊，雖然架構上還是單向的Attention，但如此一來不但包含了前文也包含了後文，也不需用到Mask。<br><img src="https://i.imgur.com/BnaxWEw.png" alt=""><br>由於架構是Transformer的Attention，在word embedding中有包含position embedding，所以用排列組合打亂句子順序其實不會對效能有太大的影響。</p>
<h3 id="Two-Stream-Self-Attention"><a href="#Two-Stream-Self-Attention" class="headerlink" title="Two-Stream Self-Attention"></a>Two-Stream Self-Attention</h3><p>在BERT中，使用Mask來告訴模型應該要預測哪一個字和前後文關係，而在XLNet中，則是使用Two-Stream Self-Attention來實現這兩種目的</p>
<h4 id="Content-Stream"><a href="#Content-Stream" class="headerlink" title="Content Stream"></a>Content Stream</h4><ul>
<li>Pre-train和Fine-tune時都會用到</li>
<li>產生Representation拿來做預測</li>
</ul>
<p><img src="https://i.imgur.com/SKiOoT3.png" alt=""></p>
<p>例如輸入序列為：{x3,x2,x4,x1}，每一個位置包含的Attention為：<br><img src="https://i.imgur.com/dUMDeB8.png" alt=""></p>
<h4 id="Query-Stream"><a href="#Query-Stream" class="headerlink" title="Query Stream"></a>Query Stream</h4><ul>
<li>只有Pre-train時用到</li>
<li>如同BERT的Mask</li>
</ul>
<p><img src="https://i.imgur.com/ZecQRMV.png" alt=""><br>Query Stream負責在Pre-train擔任預測單詞的作用，因為在預測單詞時不允許模型看到當前的token是什麼，所以作者在這邊另外設置一個representation g來去attend其他位置。下圖中發現Query Stream把當前位置的資訊Mask掉，這是為了不讓模型知道目前要預測的位置資訊，同時也有BERT的Mask效果。<br><img src="https://i.imgur.com/srUsXmE.png" alt=""></p>
<h3 id="Long-Text-Understanding"><a href="#Long-Text-Understanding" class="headerlink" title="Long Text Understanding"></a>Long Text Understanding</h3><p>在XLNet中，作者為了讓模型有大型文本的學習能力，借鑑Transformer-XL的Segment recurrence mechanism和Relative positional encoding的方法，簡單來說就是讓不同Segment之間互相Attention，公式如Eq.8，h上方波浪符表示上一個Segment所有的hidden representation。<br><img src="https://i.imgur.com/60FdzyE.png" alt=""></p>
<p>從公式就知道是用當前Segment與兩者Segment concatenate的結果進行Attention，詳細的運作方式如Fig.15，Q是當前Segment，K是上一個Segment與當前Segment的concatenation，兩個矩陣相乘後就得到右邊的長方形Attetnion matrix，因為沒有舉例要Permutation的位置，筆者這裡隨便舉一個Sequence出來，重點是排列後Sequence{z5,z7,z6,z8}，並把z6當成Target去把Attention matrix沒有attend的位置mask掉。<br><img src="https://i.imgur.com/OmHeFWq.png" alt=""></p>
<p><a href="https://medium.com/ai-academy-taiwan/2019-nlp%E6%9C%80%E5%BC%B7%E6%A8%A1%E5%9E%8B-xlnet-ac728b400de3" target="_blank" rel="external">2019-NLP最強模型: XLNet</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-10-Convolutional-Neural-Network" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-20T15:24:14.000Z"><a href="/SeanCherngTW.github.io/2019/08/20/ML-Lecture-10-Convolutional-Neural-Network/">2019-08-20</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2019/08/20/ML-Lecture-10-Convolutional-Neural-Network/">ML Lecture 10: Convolutional Neural Network</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h4 id="圖像辨識使用CNN"><a href="#圖像辨識使用CNN" class="headerlink" title="圖像辨識使用CNN"></a>圖像辨識使用CNN</h4><ul>
<li>需要辨識的物體可能只佔了圖片的某一小塊（Convolution）</li>
<li>同樣的pattern在圖片中的不同地方仍然代表一樣的意思（Convolution）</li>
<li>圖片縮小後，仍然可以輕易地分辨出圖片中的物體（pooling）</li>
</ul>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2019/08/20/ML-Lecture-10-Convolutional-Neural-Network/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-3-1-Gradient-Descent" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T15:58:13.000Z"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-3-1-Gradient-Descent/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-3-1-Gradient-Descent/">ML Lecture 3-1: Gradient Descent</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h4 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h4><ul>
<li>把輸入的特徵的值範圍調整成一致</li>
<li>可以想成標準化，平均=1、標準差=0</li>
<li>如此一來在做Gradient Descent時，可以讓梯度以直線往最低點前進，讓各參數不需要客製化自己的Learning rate
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-3-1-Gradient-Descent/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-2-Where-does-the-error-come-from" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T15:55:11.000Z"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-2-Where-does-the-error-come-from/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-2-Where-does-the-error-come-from/">ML Lecture 2: Where does the error come from?</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <p>Variance / Bias</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-2-Where-does-the-error-come-from/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-1-Regression-Case-Study" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T03:01:45.000Z"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-1-Regression-Case-Study/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-1-Regression-Case-Study/">ML Lecture 1: Regression - Case Study</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="ML三步驟"><a href="#ML三步驟" class="headerlink" title="ML三步驟"></a>ML三步驟</h3><ol>
<li>準備一組function set（設計model）<ul>
<li>可以把function set想成Model，不同的model代表不同function set</li>
<li>同一個model代表同一個function set，參數中不同的weight和bias就代表同一個function set中不同的function</li>
</ul>
</li>
<li>判斷function set中，每一個function的好壞<ul>
<li>使用Loss function來判斷function的好壞<ul>
<li>具體作法：把Training data的X作為輸入，計算function產出的y與實際的y相差多少，這個相差的值就稱為Loss（或error）</li>
<li>Loss越低，代表此function對於training data的擬合度很高，但對於testing data卻不一定也是如此（可能overfitting）</li>
</ul>
</li>
</ul>
</li>
<li>找出最佳的function<ul>
<li>使用Gradient Descent來決定function中的weight應該要如何修正<ul>
<li>function中會有很多參數（weight），對參數做偏微分後，即可得到該參數的斜率。將偏微分的結果（方向）乘上Learning rate（步伐），即可算出這個weight應該要增加或減少多少，目標是使Loss降到最低</li>
</ul>
</li>
</ul>
</li>
</ol>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-1-Regression-Case-Study/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article id="post-ML-Lecture-0-1-Introduction-of-Machine-Learning" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time class="dt-published" datetime="2019-08-19T02:52:18.000Z"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-0-1-Introduction-of-Machine-Learning/">2019-08-19</a></time>
      
      
  
    <h1 class="title"><a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-0-1-Introduction-of-Machine-Learning/">ML Lecture 0-1: Introduction of Machine Learning</a></h1>
  

    </header>
    <div class="e-content entry" itemprop="articleBody">
      
        <h3 id="AI-v-s-ML-v-s-DL"><a href="#AI-v-s-ML-v-s-DL" class="headerlink" title="AI v.s. ML v.s. DL"></a>AI v.s. ML v.s. DL</h3><ul>
<li>AI是達到人工智慧的「目標」</li>
<li>Machine Learning是達到AI的手段之一</li>
<li>Deep Learning則是Machine Learning的方法之一</li>
</ul>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/SeanCherngTW.github.io/2019/08/19/ML-Lecture-0-1-Introduction-of-Machine-Learning/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
    <a href="/SeanCherngTW.github.io/page/2/" class="alignright next">Siguiente</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Buscar">
    <input type="hidden" name="as_sitesearch" value="seancherngtw.github.io/SeanCherngTW.github.io">
  </form>
</div>


  

  
<div class="widget tag">
  <h3 class="title">Etiquetas</h3>
  <ul class="entry">
  
    <li><a href="/SeanCherngTW.github.io/tags/Jupyter-Notebook/">Jupyter Notebook</a><small>1</small></li>
  
    <li><a href="/SeanCherngTW.github.io/tags/NLP/">NLP</a><small>3</small></li>
  
    <li><a href="/SeanCherngTW.github.io/tags/Python/">Python</a><small>1</small></li>
  
    <li><a href="/SeanCherngTW.github.io/tags/TensorFlow/">TensorFlow</a><small>1</small></li>
  
    <li><a href="/SeanCherngTW.github.io/tags/李宏毅機器學習筆記/">李宏毅機器學習筆記</a><small>5</small></li>
  
    <li><a href="/SeanCherngTW.github.io/tags/深度學習/">深度學習</a><small>4</small></li>
  
    <li><a href="/SeanCherngTW.github.io/tags/網頁爬蟲/">網頁爬蟲</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Sean Cherng
  
</div>
<div class="clearfix"></div></footer>
  <script src="/SeanCherngTW.github.io/js/jquery-3.4.1.min.js"></script>
<script src="/SeanCherngTW.github.io/js/jquery.imagesloaded.min.js"></script>
<script src="/SeanCherngTW.github.io/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'SeanCherngTW';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/SeanCherngTW.github.io/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/SeanCherngTW.github.io/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
